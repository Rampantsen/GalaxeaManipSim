# ğŸš€ Galaxea Diffusion Policy è®­ç»ƒå®Œæ•´æŒ‡å—

## âœ… å®Œæ•´å®ç°æ€»ç»“

æ‰€æœ‰åŠŸèƒ½å·²å®Œæˆå¹¶æµ‹è¯•é€šè¿‡ï¼

### ğŸ“ é¡¹ç›®ç»“æ„

```
GalaxeaManipSim/
â”œâ”€â”€ galaxea_sim/
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ convert_to_diffusion_policy_with_noise.py  # æ•°æ®è½¬æ¢è„šæœ¬
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ dp_noise_filtered_dataset.py  # æ•°æ®é›†ï¼ˆå™ªå£°è¿‡æ»¤+ä¸‰ç›¸æœºï¼‰
â”œâ”€â”€ policy/dp/
â”‚   â””â”€â”€ diffusion_policy/
â”‚       â”œâ”€â”€ env_runner/
â”‚       â”‚   â””â”€â”€ galaxea_image_runner.py  # ç¯å¢ƒè¯„ä¼°å™¨ï¼ˆGymnasiumå…¼å®¹ï¼‰âœ¨
â”‚       â”œâ”€â”€ config/
â”‚       â”‚   â”œâ”€â”€ task/
â”‚       â”‚   â”‚   â””â”€â”€ galaxea_image.yaml  # ä»»åŠ¡é…ç½®æ¨¡æ¿
â”‚       â”‚   â””â”€â”€ train_galaxea_diffusion_unet_image_workspace.yaml  # è®­ç»ƒé…ç½®
â”‚       â””â”€â”€ workspace/
â”‚           â””â”€â”€ train_diffusion_unet_image_workspace.py  # æ”¯æŒenv_runner=None
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_dp_with_noise.sh  # ä¸€é”®è®­ç»ƒè„šæœ¬ â­
â”‚   â””â”€â”€ train_dp_different_configs.sh  # å¤šé…ç½®è®­ç»ƒ
â””â”€â”€ docs/
    â””â”€â”€ DP_ENV_EVALUATION.md  # ç¯å¢ƒè¯„ä¼°æ–‡æ¡£
```

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### 1. **æ•°æ®è½¬æ¢** âœ…
- ä¸‰ç›¸æœºè¾“å…¥ï¼ˆimg_head, img_left, img_rightï¼‰
- è‡ªåŠ¨resizeåˆ°224x224
- ä¿ç•™å™ªå£°æ ‡ç­¾ï¼ˆis_replan_noiseï¼‰
- ç£ç›˜æ¨¡å¼åŠ è½½ï¼ˆèŠ‚çœå†…å­˜ï¼‰

### 2. **å™ªå£°è¿‡æ»¤** âœ…
- è¿‡æ»¤åŒ…å«å™ªå£°çš„åºåˆ—
- åªç”¨éå™ªå£°å¸§è®¡ç®—normalizer
- çº¦è¿‡æ»¤16%çš„è®­ç»ƒåºåˆ—

### 3. **ä¸‰ç›¸æœºè®­ç»ƒ** âœ…
- æ¯ä¸ªç›¸æœºç‹¬ç«‹çš„RGBç¼–ç å™¨
- shape_metaæ­£ç¡®é…ç½®
- å›¾åƒcropåˆ°84x84

### 4. **ç¯å¢ƒè¯„ä¼°** âœ…
- Gymnasiumå…¼å®¹ï¼ˆä¸ä¾èµ–æ—§ç‰ˆgymï¼‰
- æ¯50ä¸ªepochè¯„ä¼°5ä¸ªepisodes
- è®°å½•æˆåŠŸç‡å’Œå¥–åŠ±åˆ°WandB
- ä½ç½®ï¼š`policy/dp/diffusion_policy/env_runner/` â­

### 5. **å†…å­˜ä¼˜åŒ–** âœ…
- æ•°æ®é›†ä½¿ç”¨ç£ç›˜æ¨¡å¼ï¼ˆReplayBuffer.create_from_pathï¼‰
- DataLoader: num_workers=2, batch_size=16
- å†…å­˜å ç”¨ï¼š~3-5GBï¼ˆè€Œä¸æ˜¯15GB+ï¼‰

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ä¸€é”®è®­ç»ƒ

```bash
./scripts/train_dp_with_noise.sh R1ProBlocksStackEasy all true
```

è¿™ä¸ªè„šæœ¬ä¼šè‡ªåŠ¨ï¼š
1. âœ… è½¬æ¢æ•°æ®ä¸ºZarræ ¼å¼
2. âœ… ç”Ÿæˆä»»åŠ¡é…ç½®
3. âœ… å¯åŠ¨è®­ç»ƒï¼ˆ1000 epochsï¼‰
4. âœ… æ¯50ä¸ªepochè¯„ä¼°5ä¸ªepisodes

### è®­ç»ƒå‚æ•°

```yaml
# æ—¶é—´é…ç½®ï¼ˆ15Hzæ§åˆ¶é¢‘ç‡ï¼‰
horizon: 16  # 1.07ç§’
n_action_steps: 8  # 0.53ç§’é¢„æµ‹
n_obs_steps: 2  # 0.13ç§’å†å²

# å†…å­˜ä¼˜åŒ–
batch_size: 16
num_workers: 2
pin_memory: False

# è¯„ä¼°é…ç½®
rollout_every: 50  # æ¯50ä¸ªepochè¯„ä¼°
n_test: 5  # 5ä¸ªæµ‹è¯•episodes
```

## ğŸ“Š ç›‘æ§è®­ç»ƒ

### WandBä»ªè¡¨æ¿

è®­ç»ƒä¼šè‡ªåŠ¨ä¸Šä¼ åˆ°ï¼š
```
https://wandb.ai/rampantsen-shanghaitech-university/galaxea_diffusion_policy
```

### å…³é”®æŒ‡æ ‡

1. **train_loss**: è®­ç»ƒæŸå¤±ï¼ˆåº”è¯¥ä¸‹é™ï¼‰
2. **test/success_rate**: æˆåŠŸç‡ï¼ˆç›®æ ‡>60%ï¼‰
3. **test/mean_score**: å¹³å‡å¥–åŠ±
4. **val_loss**: éªŒè¯æŸå¤±

### å…¸å‹è®­ç»ƒæ›²çº¿

```
Epoch 0-50:   train_losså¿«é€Ÿä¸‹é™ï¼Œsuccess_rate=0-10%
Epoch 50-100: success_rateæå‡åˆ°20-30%
Epoch 100-200: success_rateæå‡åˆ°40-60%
Epoch 200-500: success_rateç¨³å®šåœ¨60-80%
```

## ğŸ”§ é«˜çº§é…ç½®

### è°ƒæ•´è¯„ä¼°é¢‘ç‡

```bash
# æ›´é¢‘ç¹è¯„ä¼°ï¼ˆæ¯10ä¸ªepochï¼‰
cd policy/dp && python train.py \
  --config-name=train_galaxea_diffusion_unet_image_workspace \
  task=galaxea_R1ProBlocksStackEasy_all \
  training.num_epochs=1000 \
  training.device='cuda:0' \
  training.rollout_every=10 \
  task.env_runner.n_test=10 \
  exp_name='frequent_eval'
```

### ç¦ç”¨ç¯å¢ƒè¯„ä¼°ï¼ˆæ›´å¿«è®­ç»ƒï¼‰

ä¿®æ”¹ `scripts/train_dp_with_noise.sh`:
```yaml
env_runner: null
```

ç„¶åä¿®æ”¹checkpointç›‘æ§ï¼š
```yaml
checkpoint:
  topk:
    monitor_key: train_loss
    mode: min
```

### è°ƒæ•´è¶…å‚æ•°

```bash
cd policy/dp && python train.py \
  --config-name=train_galaxea_diffusion_unet_image_workspace \
  task=galaxea_R1ProBlocksStackEasy_all \
  horizon=24 \
  n_obs_steps=3 \
  n_action_steps=12 \
  dataloader.batch_size=8 \
  exp_name='custom_config'
```

## âš ï¸ å¸¸è§é—®é¢˜

### 1. OOMï¼ˆå†…å­˜ä¸è¶³ï¼‰

**ç—‡çŠ¶**: `Killed` æˆ– DataLoader worker killed

**è§£å†³**:
```bash
# å‡å°‘batch sizeå’Œworkers
dataloader.batch_size=8
dataloader.num_workers=1
```

### 2. ç»´åº¦ä¸åŒ¹é…

**ç—‡çŠ¶**: `RuntimeError: The size of tensor a (16) must match the size of tensor b (24)`

**è§£å†³**: ç¡®ä¿ä½¿ç”¨æœ€æ–°ç‰ˆçš„ `dp_noise_filtered_dataset.py`ï¼ˆç»§æ‰¿SequenceSamplerï¼‰

### 3. ç¯å¢ƒè¯„ä¼°å¤±è´¥

**ç—‡çŠ¶**: `Error locating target 'diffusion_policy.env_runner.galaxea_image_runner.GalaxeaImageRunner'`

**è§£å†³**: ç¡®ä¿æ–‡ä»¶åœ¨æ­£ç¡®ä½ç½®ï¼š
```
policy/dp/diffusion_policy/env_runner/galaxea_image_runner.py
```

### 4. Checkpointé”™è¯¯

**ç—‡çŠ¶**: `KeyError: 'test_mean_score'`

**è§£å†³**: 
- å¦‚æœå¯ç”¨env_runnerï¼šä½¿ç”¨ `monitor_key: test/mean_score`
- å¦‚æœç¦ç”¨env_runnerï¼šä½¿ç”¨ `monitor_key: train_loss`

## ğŸ“ˆ æ€§èƒ½é¢„æœŸ

### è®­ç»ƒæ—¶é—´

- æ¯ä¸ªepoch: ~6-7åˆ†é’Ÿï¼ˆ883 batchesï¼‰
- 100 epochs: ~10-11å°æ—¶
- 1000 epochs: ~100-110å°æ—¶ï¼ˆ4-5å¤©ï¼‰

### ç¯å¢ƒè¯„ä¼°æ—¶é—´

- 5ä¸ªepisodesï¼ˆä¸²è¡Œï¼‰: ~10-15ç§’
- å¯¹æ€»è®­ç»ƒæ—¶é—´å½±å“ï¼š<1%

### å†…å­˜å ç”¨

- æ•°æ®é›†åŠ è½½: ~60MBï¼ˆç£ç›˜æ¨¡å¼ï¼‰
- è®­ç»ƒæ—¶GPU: ~4-6GBï¼ˆbatch_size=16ï¼‰
- è®­ç»ƒæ—¶RAM: ~3-5GBï¼ˆnum_workers=2ï¼‰

## ğŸ¯ æˆåŠŸæ ‡å‡†

### è®­ç»ƒLoss

- åº”è¯¥ä»~0.5é™åˆ°~0.05
- å¦‚æœä¸€ç›´ä¸é™ï¼Œæ£€æŸ¥å­¦ä¹ ç‡

### æˆåŠŸç‡

| Epoch | ç›®æ ‡Success Rate |
|-------|-----------------|
| 50    | >5%             |
| 100   | >20%            |
| 200   | >40%            |
| 500   | >60%            |

## ğŸ“ å®ç°å‚è€ƒ

### å®Œå…¨æŒ‰ç…§åŸç‰ˆç»“æ„

æˆ‘ä»¬çš„å®ç°å®Œå…¨å‚è€ƒåŸç‰ˆDiffusion Policyï¼š

**æ•°æ®é›†**: å‚è€ƒ `pusht_image_dataset.py`
- ç»§æ‰¿ `BaseImageDataset`
- ä½¿ç”¨ `SequenceSampler`
- è¿”å›å›ºå®šé•¿åº¦åºåˆ—

**ç¯å¢ƒè¯„ä¼°å™¨**: å‚è€ƒ `pusht_image_runner.py`
- ç»§æ‰¿ `BaseImageRunner`
- è¿”å›WandBå…¼å®¹çš„æŒ‡æ ‡å­—å…¸
- ä½äº `diffusion_policy/env_runner/`

**åŒºåˆ«**: 
- âœ¨ æ”¯æŒGymnasiumï¼ˆè€Œä¸æ˜¯æ—§ç‰ˆgymï¼‰
- âœ¨ æ”¯æŒä¸‰ç›¸æœºè¾“å…¥
- âœ¨ æ”¯æŒå™ªå£°è¿‡æ»¤

## ğŸš€ ç°åœ¨å¼€å§‹è®­ç»ƒ

```bash
# å®Œæ•´è®­ç»ƒï¼ˆ1000 epochsï¼‰
./scripts/train_dp_with_noise.sh R1ProBlocksStackEasy all true

# æˆ–åˆ†é˜¶æ®µè®­ç»ƒ
# ç¬¬ä¸€é˜¶æ®µ: 100 epochsè§‚å¯Ÿæ•ˆæœ
cd policy/dp && python train.py \
  --config-name=train_galaxea_diffusion_unet_image_workspace \
  task=galaxea_R1ProBlocksStackEasy_all \
  training.num_epochs=100 \
  training.device='cuda:0' \
  exp_name='phase1_100epochs'

# å¦‚æœæ•ˆæœå¥½ï¼Œç»§ç»­è®­ç»ƒåˆ°1000
# training.resume=True ä¼šè‡ªåŠ¨ä»checkpointç»§ç»­
```

æ‰€æœ‰åŠŸèƒ½å·²å‡†å¤‡å°±ç»ªï¼ğŸŠ

