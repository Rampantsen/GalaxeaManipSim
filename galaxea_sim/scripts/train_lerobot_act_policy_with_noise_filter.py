"""
ä½¿ç”¨å™ªå£°è¿‡æ»¤çš„ ACT ç­–ç•¥è®­ç»ƒè„šæœ¬

ç›¸æ¯”æ™®é€šè®­ç»ƒè„šæœ¬çš„æ”¹åŠ¨ï¼š
1. ä½¿ç”¨ NoiseFilteredLeRobotDataset åŒ…è£…åŸå§‹æ•°æ®é›†
2. å™ªå£°å¸§å¯ä»¥ä½œä¸ºå†å²observationè¾“å…¥ï¼Œä½†ä¸ä½œä¸ºactioné¢„æµ‹ç›®æ ‡
3. è¿™æ ·å¯ä»¥å……åˆ†åˆ©ç”¨æ•°æ®ï¼ŒåŒæ—¶é¿å…å­¦ä¹ å™ªå£°åŠ¨ä½œ
"""

from pathlib import Path
import datetime
import torch
import tyro
import pickle

from lerobot.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata
from lerobot.datasets.utils import dataset_to_policy_features
from lerobot.policies.act.configuration_act import ACTConfig
from lerobot.policies.act.modeling_act import ACTPolicy
from lerobot.configs.types import FeatureType

from loguru import logger

# å¯¼å…¥å™ªå£°è¿‡æ»¤æ•°æ®é›†å·¥å…·
from galaxea_sim.utils.noise_filtered_dataset import create_noise_filtered_dataloader


def main(
    task: str,
    output_dir: str = "outputs/ACT",
    batch_size: int = 128,
    num_epochs: int = 300,
    learning_rate: float = 1e-4,
    num_workers: int = 4,
    # å™ªå£°è¿‡æ»¤ç›¸å…³å‚æ•°
    filter_noise: bool = True,  # æ˜¯å¦è¿‡æ»¤å™ªå£°å¸§
    noise_field_name: str = "is_replan_noise",  # å™ªå£°æ ‡è®°å­—æ®µå
    # ACTé…ç½®å‚æ•°
    chunk_size: int = 30,
    n_obs_steps: int = 1,
    drop_n_last_frames: int = 8,
):
    # åˆ›å»ºè¾“å‡ºç›®å½•
    exp_id = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    output_directory = Path(output_dir) / task / exp_id
    output_directory.mkdir(parents=True, exist_ok=True)
    
    # é€‰æ‹©è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # åŠ è½½æ•°æ®é›†å…ƒæ•°æ®
    dataset_name = task
    dataset_metadata = LeRobotDatasetMetadata(f"galaxea/{dataset_name}")
    features = dataset_to_policy_features(dataset_metadata.features)
    output_features = {key: ft for key, ft in features.items() if ft.type is FeatureType.ACTION}
    input_features = {key: ft for key, ft in features.items() if key not in output_features}
    
    # é…ç½®ACTç­–ç•¥
    cfg = ACTConfig(
        input_features=input_features,
        output_features=output_features,
        crop_shape=(224, 224),
        crop_is_random=False,
        use_separate_rgb_encoder_per_camera=True,
        optimizer_lr=learning_rate,
        n_obs_steps=n_obs_steps,
        chunk_size=chunk_size,
        drop_n_last_frames=drop_n_last_frames,
    )
    
    # åˆ›å»ºç­–ç•¥
    policy = ACTPolicy(cfg, dataset_stats=dataset_metadata.stats)
    policy.train()
    policy.to(device)
    
    # é…ç½®delta_timestamps
    delta_timestamps = {
        "observation.images.rgb_head": [0.0],
        "observation.images.rgb_left_hand": [0.0],
        "observation.images.rgb_right_hand": [0.0],
        "observation.state": [i / dataset_metadata.fps for i in cfg.observation_delta_indices],
        "action": [i / dataset_metadata.fps for i in cfg.action_delta_indices],
    }
    
    # åˆ›å»ºåŸå§‹æ•°æ®é›†
    base_dataset = LeRobotDataset(
        f"galaxea/{dataset_name}", 
        delta_timestamps=delta_timestamps
    )
    
    logger.info(f"åŸå§‹æ•°æ®é›†å¤§å°: {len(base_dataset)} å¸§")
    
    # æ ¹æ®filter_noiseå‚æ•°å†³å®šæ˜¯å¦ä½¿ç”¨å™ªå£°è¿‡æ»¤
    if filter_noise:
        logger.info("âœ… ä½¿ç”¨å™ªå£°è¿‡æ»¤æ•°æ®é›†ï¼ˆæ¨èï¼‰")
        logger.info("   - å™ªå£°å¸§å¯ä»¥ä½œä¸ºå†å²observationè¾“å…¥")
        logger.info("   - ä½†å™ªå£°å¸§ä¸ä¼šä½œä¸ºactioné¢„æµ‹ç›®æ ‡")
        
        dataloader = create_noise_filtered_dataloader(
            base_dataset,
            batch_size=batch_size,
            shuffle=True,
            num_workers=num_workers,
            pin_memory=device.type != "cpu",
            noise_field_name=noise_field_name,
        )
    else:
        logger.info("âš ï¸  æœªä½¿ç”¨å™ªå£°è¿‡æ»¤ï¼ˆå¯èƒ½ä¼šå­¦ä¹ åˆ°å™ªå£°åŠ¨ä½œï¼‰")
        
        dataloader = torch.utils.data.DataLoader(
            base_dataset,
            num_workers=num_workers,
            batch_size=batch_size,
            shuffle=True,
            pin_memory=device.type != "cpu",
            drop_last=True,
        )
    
    # è®¡ç®—è®­ç»ƒæ­¥æ•°
    training_steps = num_epochs * len(dataloader)
    log_freq = 50
    save_freq = 1000
    
    logger.info(f"è®­ç»ƒé…ç½®:")
    logger.info(f"  - æ€»epochæ•°: {num_epochs}")
    logger.info(f"  - æ¯epochæ­¥æ•°: {len(dataloader)}")
    logger.info(f"  - æ€»è®­ç»ƒæ­¥æ•°: {training_steps}")
    logger.info(f"  - Batch size: {batch_size}")
    logger.info(f"  - Learning rate: {learning_rate}")
    logger.info(f"  - Chunk size: {chunk_size}")
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = torch.optim.AdamW(policy.parameters(), lr=learning_rate)
    
    # è®­ç»ƒå¾ªç¯
    step = 0
    done = False
    
    logger.info("å¼€å§‹è®­ç»ƒ...")
    
    while not done:
        for batch in dataloader:
            batch.pop("task", None)
            batch = {k: v.to(device, non_blocking=True) for k, v in batch.items()}
            
            loss, _ = policy.forward(batch)
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
            
            if step % log_freq == 0:
                logger.info(
                    f"Step: {step}/{training_steps} | "
                    f"Loss: {loss.item():.4f} | "
                    f"LR: {optimizer.param_groups[0]['lr']:.6f} | "
                    f"Progress: {step / training_steps * 100:.1f}%"
                )
            
            if step % save_freq == 0 and step > 0:
                checkpoint_dir = output_directory / f"checkpoint-{step}"
                policy.save_pretrained(checkpoint_dir)
                with open(checkpoint_dir / "dataset_metadata.pkl", "wb") as f:
                    pickle.dump(dataset_metadata, f)
                logger.info(f"ğŸ’¾ ä¿å­˜checkpoint: {checkpoint_dir}")
            
            step += 1
            if step >= training_steps:
                done = True
                break
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_checkpoint = output_directory / "checkpoint-final"
    policy.save_pretrained(final_checkpoint)
    with open(final_checkpoint / "dataset_metadata.pkl", "wb") as f:
        pickle.dump(dataset_metadata, f)
    
    logger.info(f"âœ… è®­ç»ƒå®Œæˆï¼æœ€ç»ˆæ¨¡å‹ä¿å­˜è‡³: {final_checkpoint}")


if __name__ == "__main__":
    tyro.cli(main)

